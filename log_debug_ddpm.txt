nohup: ignoring input
2024-10-20 18:35:12.121396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-10-20 18:35:19.232734: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
W1020 18:35:20.448233 139931231245440 utils.py:10] No checkpoint found at ./checkpoints-meta/checkpoint.pth. Returned the same state as input
I1020 18:35:20.461837 139931231245440 xla_bridge.py:889] Unable to initialize backend 'cuda': 
I1020 18:35:20.461991 139931231245440 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1020 18:35:20.462800 139931231245440 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
W1020 18:35:20.463041 139931231245440 xla_bridge.py:936] An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.
I1020 18:35:21.421815 139931231245440 dataset_info.py:617] Load dataset info from /home/fredxu/tensorflow_datasets/cifar10/3.0.2
I1020 18:35:21.428974 139931231245440 dataset_info.py:709] For 'cifar10/3.0.2': fields info.[splits, supervised_keys, module_name] differ on disk and in the code. Keeping the one from code.
W1020 18:35:21.429390 139931231245440 options.py:599] options.experimental_threading is deprecated. Use options.threading instead.
W1020 18:35:21.429607 139931231245440 options.py:599] options.experimental_threading is deprecated. Use options.threading instead.
I1020 18:35:21.429924 139931231245440 dataset_builder.py:579] Reusing dataset cifar10 (/home/fredxu/tensorflow_datasets/cifar10/3.0.2)
I1020 18:35:21.431347 139931231245440 reader.py:261] Creating a tf.data.Dataset reading 1 files located in folders: /home/fredxu/tensorflow_datasets/cifar10/3.0.2.
I1020 18:35:21.564606 139931231245440 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /home/fredxu/tensorflow_datasets/cifar10/3.0.2
W1020 18:35:21.713483 139931231245440 options.py:599] options.experimental_threading is deprecated. Use options.threading instead.
W1020 18:35:21.713625 139931231245440 options.py:599] options.experimental_threading is deprecated. Use options.threading instead.
I1020 18:35:21.713843 139931231245440 dataset_builder.py:579] Reusing dataset cifar10 (/home/fredxu/tensorflow_datasets/cifar10/3.0.2)
I1020 18:35:21.714482 139931231245440 reader.py:261] Creating a tf.data.Dataset reading 1 files located in folders: /home/fredxu/tensorflow_datasets/cifar10/3.0.2.
I1020 18:35:21.755632 139931231245440 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /home/fredxu/tensorflow_datasets/cifar10/3.0.2
I1020 18:35:22.099237 139931231245440 run_lib.py:130] Starting training loop at step 0.
I1020 18:35:23.498515 139931231245440 run_lib.py:140] step: 0, training_loss: 1.00246e+00
I1020 18:35:24.087049 139931231245440 run_lib.py:153] step: 0, eval_loss: 9.99960e-01
I1020 18:35:45.749435 139931231245440 run_lib.py:140] step: 50, training_loss: 9.93603e-01
I1020 18:36:07.570262 139931231245440 run_lib.py:140] step: 100, training_loss: 9.59891e-01
I1020 18:36:07.748551 139931231245440 run_lib.py:153] step: 100, eval_loss: 9.64947e-01
I1020 18:36:29.684961 139931231245440 run_lib.py:140] step: 150, training_loss: 8.87315e-01
I1020 18:36:51.736668 139931231245440 run_lib.py:140] step: 200, training_loss: 8.09340e-01
I1020 18:36:51.915026 139931231245440 run_lib.py:153] step: 200, eval_loss: 8.38413e-01
I1020 18:37:14.011345 139931231245440 run_lib.py:140] step: 250, training_loss: 7.06952e-01
I1020 18:37:36.158380 139931231245440 run_lib.py:140] step: 300, training_loss: 6.04356e-01
I1020 18:37:36.335376 139931231245440 run_lib.py:153] step: 300, eval_loss: 6.56284e-01
I1020 18:37:58.512651 139931231245440 run_lib.py:140] step: 350, training_loss: 4.81265e-01
I1020 18:38:20.684373 139931231245440 run_lib.py:140] step: 400, training_loss: 3.77328e-01
I1020 18:38:20.861175 139931231245440 run_lib.py:153] step: 400, eval_loss: 4.51663e-01
I1020 18:38:43.038031 139931231245440 run_lib.py:140] step: 450, training_loss: 2.63757e-01
I1020 18:39:05.202909 139931231245440 run_lib.py:140] step: 500, training_loss: 1.67756e-01
I1020 18:39:05.380240 139931231245440 run_lib.py:153] step: 500, eval_loss: 2.49297e-01
I1020 18:39:27.551043 139931231245440 run_lib.py:140] step: 550, training_loss: 1.04457e-01
I1020 18:39:49.717475 139931231245440 run_lib.py:140] step: 600, training_loss: 5.66077e-02
I1020 18:39:49.894789 139931231245440 run_lib.py:153] step: 600, eval_loss: 1.11996e-01
I1020 18:40:12.083765 139931231245440 run_lib.py:140] step: 650, training_loss: 4.39186e-02
I1020 18:40:34.254370 139931231245440 run_lib.py:140] step: 700, training_loss: 3.48132e-02
I1020 18:40:34.434322 139931231245440 run_lib.py:153] step: 700, eval_loss: 7.30579e-02
I1020 18:40:56.629190 139931231245440 run_lib.py:140] step: 750, training_loss: 3.49451e-02
I1020 18:41:18.816581 139931231245440 run_lib.py:140] step: 800, training_loss: 5.83525e-02
I1020 18:41:18.996765 139931231245440 run_lib.py:153] step: 800, eval_loss: 3.92309e-02
I1020 18:41:41.212433 139931231245440 run_lib.py:140] step: 850, training_loss: 4.07244e-02
I1020 18:42:03.420309 139931231245440 run_lib.py:140] step: 900, training_loss: 3.86038e-02
I1020 18:42:03.599053 139931231245440 run_lib.py:153] step: 900, eval_loss: 4.05083e-02
I1020 18:42:25.788943 139931231245440 run_lib.py:140] step: 950, training_loss: 3.46741e-02
I1020 18:42:47.992008 139931231245440 run_lib.py:140] step: 1000, training_loss: 4.07956e-02
I1020 18:42:48.171128 139931231245440 run_lib.py:153] step: 1000, eval_loss: 2.60942e-02
I1020 18:43:10.374142 139931231245440 run_lib.py:140] step: 1050, training_loss: 4.12419e-02
I1020 18:43:32.569348 139931231245440 run_lib.py:140] step: 1100, training_loss: 4.33397e-02
I1020 18:43:32.747462 139931231245440 run_lib.py:153] step: 1100, eval_loss: 4.64180e-02
I1020 18:43:54.960246 139931231245440 run_lib.py:140] step: 1150, training_loss: 3.98799e-02
I1020 18:44:17.170248 139931231245440 run_lib.py:140] step: 1200, training_loss: 3.93504e-02
I1020 18:44:17.347534 139931231245440 run_lib.py:153] step: 1200, eval_loss: 3.26160e-02
I1020 18:44:39.561622 139931231245440 run_lib.py:140] step: 1250, training_loss: 3.67861e-02
I1020 18:45:01.781833 139931231245440 run_lib.py:140] step: 1300, training_loss: 3.52216e-02
I1020 18:45:01.961165 139931231245440 run_lib.py:153] step: 1300, eval_loss: 3.27240e-02
I1020 18:45:24.164654 139931231245440 run_lib.py:140] step: 1350, training_loss: 3.94942e-02
I1020 18:45:46.368309 139931231245440 run_lib.py:140] step: 1400, training_loss: 4.63570e-02
I1020 18:45:46.549705 139931231245440 run_lib.py:153] step: 1400, eval_loss: 3.31346e-02
I1020 18:46:08.753784 139931231245440 run_lib.py:140] step: 1450, training_loss: 3.74932e-02
I1020 18:46:30.959711 139931231245440 run_lib.py:140] step: 1500, training_loss: 4.18467e-02
I1020 18:46:31.138638 139931231245440 run_lib.py:153] step: 1500, eval_loss: 2.95438e-02
I1020 18:46:53.314916 139931231245440 run_lib.py:140] step: 1550, training_loss: 3.43607e-02
I1020 18:47:15.526398 139931231245440 run_lib.py:140] step: 1600, training_loss: 3.85280e-02
I1020 18:47:15.705057 139931231245440 run_lib.py:153] step: 1600, eval_loss: 4.02474e-02
I1020 18:47:37.904650 139931231245440 run_lib.py:140] step: 1650, training_loss: 3.70391e-02
I1020 18:48:00.118227 139931231245440 run_lib.py:140] step: 1700, training_loss: 3.20941e-02
I1020 18:48:00.296877 139931231245440 run_lib.py:153] step: 1700, eval_loss: 4.65674e-02
I1020 18:48:22.497644 139931231245440 run_lib.py:140] step: 1750, training_loss: 3.19336e-02
I1020 18:48:44.697178 139931231245440 run_lib.py:140] step: 1800, training_loss: 4.72884e-02
I1020 18:48:44.876340 139931231245440 run_lib.py:153] step: 1800, eval_loss: 3.43133e-02
I1020 18:49:07.060433 139931231245440 run_lib.py:140] step: 1850, training_loss: 3.80901e-02
I1020 18:49:29.280953 139931231245440 run_lib.py:140] step: 1900, training_loss: 3.94859e-02
I1020 18:49:29.459734 139931231245440 run_lib.py:153] step: 1900, eval_loss: 4.79970e-02
I1020 18:49:51.678075 139931231245440 run_lib.py:140] step: 1950, training_loss: 3.90413e-02
I1020 18:50:13.884191 139931231245440 run_lib.py:140] step: 2000, training_loss: 3.42149e-02
I1020 18:50:14.064770 139931231245440 run_lib.py:153] step: 2000, eval_loss: 3.25947e-02
I1020 18:50:36.295700 139931231245440 run_lib.py:140] step: 2050, training_loss: 4.38563e-02
I1020 18:50:58.534951 139931231245440 run_lib.py:140] step: 2100, training_loss: 3.35254e-02
I1020 18:50:58.712168 139931231245440 run_lib.py:153] step: 2100, eval_loss: 3.29632e-02
I1020 18:51:20.911321 139931231245440 run_lib.py:140] step: 2150, training_loss: 4.33109e-02
I1020 18:51:43.116884 139931231245440 run_lib.py:140] step: 2200, training_loss: 4.28395e-02
I1020 18:51:43.295383 139931231245440 run_lib.py:153] step: 2200, eval_loss: 3.38878e-02
I1020 18:52:05.520617 139931231245440 run_lib.py:140] step: 2250, training_loss: 3.93788e-02
I1020 18:52:27.739204 139931231245440 run_lib.py:140] step: 2300, training_loss: 3.98099e-02
I1020 18:52:27.917682 139931231245440 run_lib.py:153] step: 2300, eval_loss: 3.71499e-02
I1020 18:52:50.116483 139931231245440 run_lib.py:140] step: 2350, training_loss: 3.17909e-02
I1020 18:53:12.332285 139931231245440 run_lib.py:140] step: 2400, training_loss: 3.17163e-02
I1020 18:53:12.511887 139931231245440 run_lib.py:153] step: 2400, eval_loss: 3.19266e-02
I1020 18:53:34.727001 139931231245440 run_lib.py:140] step: 2450, training_loss: 3.77669e-02
I1020 18:53:56.953288 139931231245440 run_lib.py:140] step: 2500, training_loss: 3.42927e-02
I1020 18:53:57.132347 139931231245440 run_lib.py:153] step: 2500, eval_loss: 2.46261e-02
I1020 18:54:19.339942 139931231245440 run_lib.py:140] step: 2550, training_loss: 4.50989e-02
I1020 18:54:41.557245 139931231245440 run_lib.py:140] step: 2600, training_loss: 2.97271e-02
I1020 18:54:41.735574 139931231245440 run_lib.py:153] step: 2600, eval_loss: 3.84536e-02
I1020 18:55:03.929562 139931231245440 run_lib.py:140] step: 2650, training_loss: 3.06354e-02
I1020 18:55:26.131706 139931231245440 run_lib.py:140] step: 2700, training_loss: 3.15216e-02
I1020 18:55:26.309217 139931231245440 run_lib.py:153] step: 2700, eval_loss: 3.33351e-02
I1020 18:55:48.494077 139931231245440 run_lib.py:140] step: 2750, training_loss: 4.11124e-02
I1020 18:56:10.686756 139931231245440 run_lib.py:140] step: 2800, training_loss: 3.57267e-02
I1020 18:56:10.864766 139931231245440 run_lib.py:153] step: 2800, eval_loss: 3.17162e-02
I1020 18:56:33.072079 139931231245440 run_lib.py:140] step: 2850, training_loss: 3.26253e-02
I1020 18:56:55.277957 139931231245440 run_lib.py:140] step: 2900, training_loss: 3.50260e-02
I1020 18:56:55.455732 139931231245440 run_lib.py:153] step: 2900, eval_loss: 4.60881e-02
I1020 18:57:17.674201 139931231245440 run_lib.py:140] step: 2950, training_loss: 2.21645e-02
I1020 18:57:39.903535 139931231245440 run_lib.py:140] step: 3000, training_loss: 3.46716e-02
I1020 18:57:40.081154 139931231245440 run_lib.py:153] step: 3000, eval_loss: 4.05199e-02
I1020 18:58:02.269334 139931231245440 run_lib.py:140] step: 3050, training_loss: 2.51917e-02
I1020 18:58:24.468044 139931231245440 run_lib.py:140] step: 3100, training_loss: 3.37801e-02
I1020 18:58:24.647165 139931231245440 run_lib.py:153] step: 3100, eval_loss: 2.87272e-02
I1020 18:58:46.860232 139931231245440 run_lib.py:140] step: 3150, training_loss: 3.04804e-02
I1020 18:59:09.046160 139931231245440 run_lib.py:140] step: 3200, training_loss: 3.68033e-02
I1020 18:59:09.223819 139931231245440 run_lib.py:153] step: 3200, eval_loss: 3.12022e-02
I1020 18:59:31.417881 139931231245440 run_lib.py:140] step: 3250, training_loss: 4.00002e-02
I1020 18:59:53.622922 139931231245440 run_lib.py:140] step: 3300, training_loss: 3.30811e-02
I1020 18:59:53.801457 139931231245440 run_lib.py:153] step: 3300, eval_loss: 3.49643e-02
I1020 19:00:16.004065 139931231245440 run_lib.py:140] step: 3350, training_loss: 3.26318e-02
I1020 19:00:38.204496 139931231245440 run_lib.py:140] step: 3400, training_loss: 3.75327e-02
I1020 19:00:38.383774 139931231245440 run_lib.py:153] step: 3400, eval_loss: 3.42654e-02
I1020 19:01:00.593628 139931231245440 run_lib.py:140] step: 3450, training_loss: 2.50168e-02
I1020 19:01:22.817177 139931231245440 run_lib.py:140] step: 3500, training_loss: 3.63587e-02
I1020 19:01:22.993495 139931231245440 run_lib.py:153] step: 3500, eval_loss: 3.38725e-02
I1020 19:01:45.188677 139931231245440 run_lib.py:140] step: 3550, training_loss: 3.01923e-02
I1020 19:02:07.392860 139931231245440 run_lib.py:140] step: 3600, training_loss: 2.70298e-02
I1020 19:02:07.571931 139931231245440 run_lib.py:153] step: 3600, eval_loss: 3.14158e-02
I1020 19:02:29.801451 139931231245440 run_lib.py:140] step: 3650, training_loss: 3.65540e-02
I1020 19:02:52.017183 139931231245440 run_lib.py:140] step: 3700, training_loss: 2.65171e-02
I1020 19:02:52.195755 139931231245440 run_lib.py:153] step: 3700, eval_loss: 3.92907e-02
I1020 19:03:14.408609 139931231245440 run_lib.py:140] step: 3750, training_loss: 2.91608e-02
I1020 19:03:36.617976 139931231245440 run_lib.py:140] step: 3800, training_loss: 3.78071e-02
I1020 19:03:36.797302 139931231245440 run_lib.py:153] step: 3800, eval_loss: 2.55742e-02
I1020 19:03:59.008256 139931231245440 run_lib.py:140] step: 3850, training_loss: 3.05324e-02
I1020 19:04:21.210656 139931231245440 run_lib.py:140] step: 3900, training_loss: 3.89864e-02
I1020 19:04:21.391075 139931231245440 run_lib.py:153] step: 3900, eval_loss: 3.09206e-02
I1020 19:04:43.600717 139931231245440 run_lib.py:140] step: 3950, training_loss: 4.03356e-02
I1020 19:05:05.803158 139931231245440 run_lib.py:140] step: 4000, training_loss: 3.21378e-02
I1020 19:05:05.981428 139931231245440 run_lib.py:153] step: 4000, eval_loss: 3.72043e-02
I1020 19:05:28.173801 139931231245440 run_lib.py:140] step: 4050, training_loss: 3.55149e-02
I1020 19:05:50.364016 139931231245440 run_lib.py:140] step: 4100, training_loss: 3.24114e-02
I1020 19:05:50.541869 139931231245440 run_lib.py:153] step: 4100, eval_loss: 2.95963e-02
I1020 19:06:12.781413 139931231245440 run_lib.py:140] step: 4150, training_loss: 2.20643e-02
I1020 19:06:35.016674 139931231245440 run_lib.py:140] step: 4200, training_loss: 2.45283e-02
I1020 19:06:35.194780 139931231245440 run_lib.py:153] step: 4200, eval_loss: 3.64631e-02
I1020 19:06:57.400079 139931231245440 run_lib.py:140] step: 4250, training_loss: 3.39601e-02
I1020 19:07:19.604432 139931231245440 run_lib.py:140] step: 4300, training_loss: 3.85277e-02
I1020 19:07:19.783777 139931231245440 run_lib.py:153] step: 4300, eval_loss: 4.04160e-02
I1020 19:07:41.993724 139931231245440 run_lib.py:140] step: 4350, training_loss: 2.90866e-02
I1020 19:08:04.202340 139931231245440 run_lib.py:140] step: 4400, training_loss: 4.37367e-02
I1020 19:08:04.381396 139931231245440 run_lib.py:153] step: 4400, eval_loss: 2.63376e-02
I1020 19:08:26.590404 139931231245440 run_lib.py:140] step: 4450, training_loss: 3.72468e-02
I1020 19:08:48.804573 139931231245440 run_lib.py:140] step: 4500, training_loss: 3.70527e-02
I1020 19:08:48.981392 139931231245440 run_lib.py:153] step: 4500, eval_loss: 3.29336e-02
I1020 19:09:11.177538 139931231245440 run_lib.py:140] step: 4550, training_loss: 2.42945e-02
I1020 19:09:33.389882 139931231245440 run_lib.py:140] step: 4600, training_loss: 2.58294e-02
I1020 19:09:33.568898 139931231245440 run_lib.py:153] step: 4600, eval_loss: 3.78473e-02
I1020 19:09:55.773956 139931231245440 run_lib.py:140] step: 4650, training_loss: 2.25257e-02
I1020 19:10:17.974948 139931231245440 run_lib.py:140] step: 4700, training_loss: 4.62198e-02
I1020 19:10:18.152399 139931231245440 run_lib.py:153] step: 4700, eval_loss: 3.11712e-02
I1020 19:10:40.343455 139931231245440 run_lib.py:140] step: 4750, training_loss: 3.25951e-02
I1020 19:11:02.550468 139931231245440 run_lib.py:140] step: 4800, training_loss: 3.52487e-02
I1020 19:11:02.728930 139931231245440 run_lib.py:153] step: 4800, eval_loss: 3.57688e-02
I1020 19:11:24.945094 139931231245440 run_lib.py:140] step: 4850, training_loss: 3.71160e-02
I1020 19:11:47.152547 139931231245440 run_lib.py:140] step: 4900, training_loss: 2.71006e-02
I1020 19:11:47.331803 139931231245440 run_lib.py:153] step: 4900, eval_loss: 3.03508e-02
I1020 19:12:09.559391 139931231245440 run_lib.py:140] step: 4950, training_loss: 2.29911e-02
I1020 19:12:31.792935 139931231245440 run_lib.py:140] step: 5000, training_loss: 3.53439e-02
I1020 19:12:31.969455 139931231245440 run_lib.py:153] step: 5000, eval_loss: 3.77389e-02
I1020 19:12:54.217176 139931231245440 run_lib.py:140] step: 5050, training_loss: 3.26924e-02
I1020 19:13:16.443282 139931231245440 run_lib.py:140] step: 5100, training_loss: 3.69361e-02
I1020 19:13:16.627144 139931231245440 run_lib.py:153] step: 5100, eval_loss: 2.52194e-02
I1020 19:13:38.877175 139931231245440 run_lib.py:140] step: 5150, training_loss: 3.88626e-02
I1020 19:14:01.116957 139931231245440 run_lib.py:140] step: 5200, training_loss: 2.83030e-02
I1020 19:14:01.295140 139931231245440 run_lib.py:153] step: 5200, eval_loss: 2.86097e-02
I1020 19:14:23.533652 139931231245440 run_lib.py:140] step: 5250, training_loss: 2.50993e-02
I1020 19:14:45.776560 139931231245440 run_lib.py:140] step: 5300, training_loss: 4.00985e-02
I1020 19:14:45.955869 139931231245440 run_lib.py:153] step: 5300, eval_loss: 3.97763e-02
I1020 19:15:08.209662 139931231245440 run_lib.py:140] step: 5350, training_loss: 3.24326e-02
I1020 19:15:30.467621 139931231245440 run_lib.py:140] step: 5400, training_loss: 2.85225e-02
I1020 19:15:30.653373 139931231245440 run_lib.py:153] step: 5400, eval_loss: 3.40385e-02
I1020 19:15:52.887174 139931231245440 run_lib.py:140] step: 5450, training_loss: 3.88265e-02
I1020 19:16:15.124632 139931231245440 run_lib.py:140] step: 5500, training_loss: 2.81884e-02
I1020 19:16:15.308915 139931231245440 run_lib.py:153] step: 5500, eval_loss: 3.36501e-02
I1020 19:16:37.564611 139931231245440 run_lib.py:140] step: 5550, training_loss: 2.59725e-02
I1020 19:16:59.786953 139931231245440 run_lib.py:140] step: 5600, training_loss: 3.86051e-02
I1020 19:16:59.964804 139931231245440 run_lib.py:153] step: 5600, eval_loss: 4.20938e-02
I1020 19:17:22.267463 139931231245440 run_lib.py:140] step: 5650, training_loss: 3.42628e-02
I1020 19:17:44.541232 139931231245440 run_lib.py:140] step: 5700, training_loss: 4.12531e-02
I1020 19:17:44.718522 139931231245440 run_lib.py:153] step: 5700, eval_loss: 2.66614e-02
I1020 19:18:06.941141 139931231245440 run_lib.py:140] step: 5750, training_loss: 2.89183e-02
I1020 19:18:29.182152 139931231245440 run_lib.py:140] step: 5800, training_loss: 1.77650e-02
I1020 19:18:29.360619 139931231245440 run_lib.py:153] step: 5800, eval_loss: 3.40467e-02
I1020 19:18:51.592412 139931231245440 run_lib.py:140] step: 5850, training_loss: 2.45720e-02
I1020 19:19:13.836582 139931231245440 run_lib.py:140] step: 5900, training_loss: 3.77729e-02
I1020 19:19:14.015617 139931231245440 run_lib.py:153] step: 5900, eval_loss: 3.50760e-02
I1020 19:19:36.253015 139931231245440 run_lib.py:140] step: 5950, training_loss: 2.11282e-02
I1020 19:19:58.491335 139931231245440 run_lib.py:140] step: 6000, training_loss: 2.65083e-02
I1020 19:19:58.674989 139931231245440 run_lib.py:153] step: 6000, eval_loss: 2.53466e-02
I1020 19:20:20.930249 139931231245440 run_lib.py:140] step: 6050, training_loss: 2.68646e-02
I1020 19:20:43.178193 139931231245440 run_lib.py:140] step: 6100, training_loss: 2.75924e-02
I1020 19:20:43.363773 139931231245440 run_lib.py:153] step: 6100, eval_loss: 3.70201e-02
I1020 19:21:05.626881 139931231245440 run_lib.py:140] step: 6150, training_loss: 3.53089e-02
I1020 19:21:27.871667 139931231245440 run_lib.py:140] step: 6200, training_loss: 3.59276e-02
I1020 19:21:28.050343 139931231245440 run_lib.py:153] step: 6200, eval_loss: 3.11987e-02
I1020 19:21:50.330364 139931231245440 run_lib.py:140] step: 6250, training_loss: 3.34953e-02
I1020 19:22:12.585502 139931231245440 run_lib.py:140] step: 6300, training_loss: 2.72008e-02
I1020 19:22:12.765360 139931231245440 run_lib.py:153] step: 6300, eval_loss: 3.00515e-02
I1020 19:22:34.986550 139931231245440 run_lib.py:140] step: 6350, training_loss: 3.30097e-02
I1020 19:22:57.210681 139931231245440 run_lib.py:140] step: 6400, training_loss: 2.30050e-02
I1020 19:22:57.392047 139931231245440 run_lib.py:153] step: 6400, eval_loss: 3.02816e-02
I1020 19:23:19.653825 139931231245440 run_lib.py:140] step: 6450, training_loss: 2.67331e-02
I1020 19:23:41.928978 139931231245440 run_lib.py:140] step: 6500, training_loss: 3.27727e-02
I1020 19:23:42.109736 139931231245440 run_lib.py:153] step: 6500, eval_loss: 3.27817e-02
I1020 19:24:04.349241 139931231245440 run_lib.py:140] step: 6550, training_loss: 3.58869e-02
I1020 19:24:26.567179 139931231245440 run_lib.py:140] step: 6600, training_loss: 3.66594e-02
I1020 19:24:26.745716 139931231245440 run_lib.py:153] step: 6600, eval_loss: 3.59886e-02
I1020 19:24:48.987610 139931231245440 run_lib.py:140] step: 6650, training_loss: 2.30090e-02
I1020 19:25:11.229139 139931231245440 run_lib.py:140] step: 6700, training_loss: 4.15932e-02
I1020 19:25:11.408454 139931231245440 run_lib.py:153] step: 6700, eval_loss: 3.24737e-02
I1020 19:25:33.646406 139931231245440 run_lib.py:140] step: 6750, training_loss: 4.62412e-02
I1020 19:25:55.888308 139931231245440 run_lib.py:140] step: 6800, training_loss: 2.68467e-02
I1020 19:25:56.067478 139931231245440 run_lib.py:153] step: 6800, eval_loss: 2.90605e-02
I1020 19:26:18.303790 139931231245440 run_lib.py:140] step: 6850, training_loss: 3.54433e-02
I1020 19:26:40.542588 139931231245440 run_lib.py:140] step: 6900, training_loss: 2.73542e-02
I1020 19:26:40.721369 139931231245440 run_lib.py:153] step: 6900, eval_loss: 3.40370e-02
I1020 19:27:02.990551 139931231245440 run_lib.py:140] step: 6950, training_loss: 4.04236e-02
I1020 19:27:25.223913 139931231245440 run_lib.py:140] step: 7000, training_loss: 3.08986e-02
I1020 19:27:25.402281 139931231245440 run_lib.py:153] step: 7000, eval_loss: 3.74065e-02
I1020 19:27:47.686959 139931231245440 run_lib.py:140] step: 7050, training_loss: 2.95283e-02
I1020 19:28:09.968579 139931231245440 run_lib.py:140] step: 7100, training_loss: 2.81590e-02
I1020 19:28:10.149533 139931231245440 run_lib.py:153] step: 7100, eval_loss: 3.04073e-02
I1020 19:28:32.382550 139931231245440 run_lib.py:140] step: 7150, training_loss: 3.90309e-02
I1020 19:28:54.621138 139931231245440 run_lib.py:140] step: 7200, training_loss: 2.91649e-02
I1020 19:28:54.801535 139931231245440 run_lib.py:153] step: 7200, eval_loss: 3.19136e-02
I1020 19:29:17.028245 139931231245440 run_lib.py:140] step: 7250, training_loss: 3.49290e-02
I1020 19:29:39.270189 139931231245440 run_lib.py:140] step: 7300, training_loss: 2.41398e-02
I1020 19:29:39.449473 139931231245440 run_lib.py:153] step: 7300, eval_loss: 2.38980e-02
I1020 19:30:01.699837 139931231245440 run_lib.py:140] step: 7350, training_loss: 3.41439e-02
I1020 19:30:23.978140 139931231245440 run_lib.py:140] step: 7400, training_loss: 3.51107e-02
I1020 19:30:24.159778 139931231245440 run_lib.py:153] step: 7400, eval_loss: 3.25305e-02
I1020 19:30:46.399855 139931231245440 run_lib.py:140] step: 7450, training_loss: 2.94996e-02
I1020 19:31:08.639203 139931231245440 run_lib.py:140] step: 7500, training_loss: 3.47446e-02
I1020 19:31:08.821013 139931231245440 run_lib.py:153] step: 7500, eval_loss: 2.16085e-02
